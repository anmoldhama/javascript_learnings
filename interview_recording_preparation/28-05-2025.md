üîÑ Core Node.js Concepts
1. What is the difference between microtask and macrotask queues in Node.js? How does this affect setTimeout, Promise, and nextTick?
ans : 

2. How does the libuv library help Node.js achieve concurrency on a single thread?
ans : 

3. What is the purpose of process.nextTick() and how is it different from setImmediate()?
ans : 

3. How does Node.js handle backpressure in streams? How would you implement custom logic for it?
ans : 
Backpressure: When data is being produced faster than it‚Äôs being consumed, a writable stream‚Äôs internal buffer can fill up. Node.js streams mechanism gives you ways to detect and respond to this situation.

How built-in streams handle it:
Readable stream: emits a 'data' event (in flowing mode) or allows you to call .read() manually (in paused mode).

Writable stream: provides a .write(chunk) method that returns a boolean:

If .write() returns true, the writable stream‚Äôs buffer is below its high‚Äêwater mark, and you may continue writing.

If .write() returns false, the writable stream‚Äôs buffer is full (exceeded highWaterMark), and you should stop writing until the 'drain' event fires.

Implementing custom backpressure logic:
Using built-in Transform streams

If you write a custom Transform or Duplex, call this.push(data) only when the internal readable buffer has space. If this.push(data) returns false, pause your data source or stop pushing until a 'drain' or 'readable' event tells you it‚Äôs okay to resume.

Manual mode

js
Copy
Edit
const readable = getSomeReadableStream();
const writable = getSomeWritableStream();

readable.on("data", (chunk) => {
  // Try writing to writable
  const ok = writable.write(chunk);
  if (!ok) {
    // Backpressure: pause the readable until 'drain'
    readable.pause();
    writable.once("drain", () => {
      // Resume readable once writable has drained
      readable.resume();
    });
  }
});

readable.on("end", () => writable.end());
Example: Simulate a slower consumer

js
Copy
Edit
const { Readable, Writable } = require("stream");

class FastSource extends Readable {
  constructor() {
    super({ highWaterMark: 16 });
    this._i = 0;
  }
  _read() {
    // produce data super fast
    while (this.push(`chunk${this._i++}`)) {
      if (this._i > 100) {
        return this.push(null); // no more data
      }
    }
    // if push() returned false, stop until downstream drains
  }
}

class SlowSink extends Writable {
  constructor() {
    super({ highWaterMark: 16 });
  }
  _write(chunk, encoding, cb) {
    console.log("Writing:", chunk.toString());
    // simulate async delay
    setTimeout(cb, 100);
  }
}

const fast = new FastSource();
const slow = new SlowSink();

// Pipe automatically handles backpressure:
fast.pipe(slow);

4. Explain the phases of the Node.js Event Loop and which operations run in each phase
ans : The Node.js Event Loop consists of six main phases (plus timers and close callbacks). These are:

Timers (check)

Executes callbacks scheduled by setTimeout and setInterval whose threshold has been reached.

Pending Callbacks

Executes I/O callbacks deferred to the next loop iteration (e.g., some TCP errors, certain kinds of system ops).

Idle, Prepare

Internal phase used by Node.js itself (not directly accessible by JS).

Poll

Retrieves new I/O events; executes I/O related callbacks (TCP/UDP data, filesystem callbacks, etc.).

If there are no timers scheduled, and no immediate tasks, it will wait here for callbacks (unless forced to move on).

Check

Executes setImmediate callbacks.

Close Callbacks

Executes callbacks for closed connections, e.g. 'close' events on sockets or handles.

Microtasks & nextTick Hooks
process.nextTick callbacks always run immediately after the current callback, before the Event Loop moves to the next phase.

Promises (microtasks): runs after nextTick callbacks, but before returning to the Event Loop phases.

Rough Order
Execute a callback (e.g., from a timer or I/O).

Drain the nextTick queue.

Drain the microtask (Promises) queue.

Continue to the next Event Loop phase (timers ‚Üí pending callbacks ‚Üí poll ‚Üí check ‚Üí close).

Within each phase, after callbacks complete, drain nextTick and microtasks before moving to the next phase.



üß± Modules, Patterns, and Architecture
5. Compare CommonJS and ES Modules in Node.js. What are some pitfalls of mixing them?
ans : 

6. How would you implement the singleton pattern in a Node.js module?
ans : 

7. What is tree shaking and how does it relate to module exports in Node.js?
ans : 
Tree shaking is a build‚Äêtime optimization that removes unused code (dead code elimination).

In a bundler (Webpack, Rollup, ESBuild, Vite, etc.), if you use ES Modules (import { a, b } from "./lib";), the bundler can statically analyze which named exports you actually use. Unused exports are ‚Äúshaken out‚Äù of the final bundle.

8. Explain how circular dependencies are handled in Node.js.
ans : 
CommonJS (CJS) Circular Dependencies
When two modules A and B require each other, Node.js will:

Start loading A: create an empty module.exports = {} object and begin executing A.

A does const B = require("./B"). Node sees B is not yet loaded ‚Üí starts loading B: create module.exports for B, begin executing B.

B does const A = require("./A"). Node sees A is currently loading, so it returns the partially filled module.exports of A (which is currently an empty object or whatever A has assigned so far).

B finishes execution, populating its own module.exports. Then control returns to A, which completes and populates its module.exports.

Result:

If A tries to access properties of B too early (before B has fully populated them), it may see undefined.

If B tries to access A before A finishes, it will get the partial A.exports.

ES Modules (ESM) Circular Dependencies
ESM uses live bindings. When you do import { foo } from "./A", you get a reference to A‚Äôs foo export, not a copy. If A updates foo later, that new value appears to B.

If A and B import each other, each sees the other‚Äôs exports object‚Äîthough some exports may not yet be initialized at the moment of import. Accessing an uninitialized binding throws a runtime error.


9. How would you design a plugin-based architecture using dynamic imports in Node.js?

üì¶ APIs, HTTP, and Middleware
10. What are the key differences between http.createServer() and using a framework like Express?
ans :
Low-level vs High-level

http.createServer((req, res) => { ‚Ä¶ }) gives you raw IncomingMessage and ServerResponse objects. You must manually parse URL-encoded body, JSON body, query strings, cookies, routes, etc.

Express (or Koa, Fastify, etc.) abstracts away boilerplate: you get req.body, req.params, req.query, req.cookies, routing, middleware chaining, etc.

Routing

With http.createServer(), you check req.url/req.method manually or use a third‚Äêparty router.

Express has built‚Äêin app.get("/users/:id", handler) style routing, param parsing, etc.

Middleware

In plain http.createServer(), you‚Äôd write custom code inside a single callback.

Express supports middleware functions (app.use(‚Ä¶)) that run in sequence, e.g. for logging, parsing, authentication, error handling, etc.

Error Handling

In http.createServer, you must wrap everything in try/catch and manually .writeHead(500) on error.

Express has a default error‚Äêhandling middleware or you can define app.use((err, req, res, next) => { ‚Ä¶ }). If a route handler throws or calls next(err), Express routes it to the error middleware.

Features out-of-the-box

Express: cookie parsing, session handling, templating engines, CORS, request validation, etc.

http.createServer: you manually wire libraries or write your own.

11. How would you manually parse application/x-www-form-urlencoded data in a Node.js server without using middleware?
ans :
If you‚Äôre using http.createServer(), you get raw request body data in chunks. You can accumulate it and then parse using querystring (or manually split on & and =).

const http = require("http");
const { parse: parseQS } = require("querystring");

const server = http.createServer((req, res) => {
  if (req.method === "POST" && req.headers["content-type"] === "application/x-www-form-urlencoded") {
    let body = "";
    req.on("data", (chunk) => {
      body += chunk.toString(); // accumulate
      // Optional: You can check if body.length > some limit, then destroy connection
    });
    req.on("end", () => {
      // Now `body` is something like "username=alice&password=secret"
      const parsed = parseQS(body); // e.g. { username: "alice", password: "secret" }
      res.writeHead(200, { "Content-Type": "application/json" });
      res.end(JSON.stringify(parsed));
    });
  } else {
    res.writeHead(404);
    res.end();
  }
});

server.listen(3000);
Note: For large uploads, monitor body.length to avoid a DoS by large payloads. You can also check req.headers["content-length"] before reading the body.


12. What are the implications of Content-Length vs Transfer-Encoding: chunked in streaming responses?
ans :

Indicates the exact byte length of the entire response body up front.

Client knows when the full response is received by reading exactly that many bytes.

If you know the size in advance (e.g. reading a file out of disk), you set Content-Length and then stream the file.

No extra framing needed‚Äîclient reads until the specified number of bytes.

Transfer-Encoding: chunked

Splits the response into chunks. Each chunk is prefixed by its size in hex, followed by CRLF, then the chunk data, then another CRLF. A zero‚Äêlength chunk (0\r\n\r\n) marks end of response.

Use when you don‚Äôt know the total size in advance (e.g. dynamically generating HTML or sending data as it becomes available).

Client reads until it encounters 0\r\n\r\n, rather than reading an explicit length.

Slight overhead: each chunk has <length>\r\n<data>\r\n wrapping.


13. How can you implement rate limiting in Node.js without any external libraries?
ans :
You can implement a simple in‚Äêmemory rate limiter using a token bucket or fixed window counter. Below is a basic fixed window approach keyed by client IP (or API key):

const http = require("http");

const RATE_LIMIT = 100;          // max requests
const WINDOW_MS = 60 * 1000;     // per minute

// Store counts in an object: { ip: { count, windowStart } }
const requestCounts = {};

function rateLimiter(req, res) {
  const ip = req.socket.remoteAddress || "unknown";
  const now = Date.now();

  if (!requestCounts[ip]) {
    requestCounts[ip] = { count: 1, windowStart: now };
  } else {
    const entry = requestCounts[ip];
    if (now - entry.windowStart < WINDOW_MS) {
      // still inside current window
      entry.count += 1;
    } else {
      // window has expired, reset
      entry.count = 1;
      entry.windowStart = now;
    }
  }

  if (requestCounts[ip].count > RATE_LIMIT) {
    res.writeHead(429, { "Content-Type": "text/plain" });
    res.end("Too Many Requests\n");
    return false;
  }

  return true;
}

const server = http.createServer((req, res) => {
  if (!rateLimiter(req, res)) return;

  // Normal handling
  res.writeHead(200, { "Content-Type": "text/plain" });
  res.end("Hello, world!\n");
});

server.listen(3000);

Pros: Simple to implement.

Cons: In‚Äêmemory; does not scale across multiple processes or servers. Can be abused if many IP keys fill up memory.

14. What are middleware chaining patterns and how would you implement your own mini Express-like middleware system?
ans :
Middleware is a series of functions that each receive (req, res, next) and either:

Modify req/res and call next() to pass control to the next middleware, or

Send a response and not call next(), thereby terminating the chain.

const http = require("http");

function compose(middlewares) {
  return (req, res) => {
    let idx = 0;
    function next(err) {
      if (err) {
        return res.end("Error: " + err);
      }
      const middleware = middlewares[idx++];
      if (!middleware) {
        return; // no more middleware
      }
      try {
        middleware(req, res, next);
      } catch (e) {
        next(e);
      }
    }
    next(); // start chain
  };
}

// Example middleware
function logger(req, res, next) {
  console.log(`${req.method} ${req.url}`);
  next();
}

function auth(req, res, next) {
  if (req.headers["x-api-key"] === "secret") {
    next();
  } else {
    res.writeHead(401);
    res.end("Unauthorized");
  }
}

function handler(req, res) {
  res.writeHead(200);
  res.end("Success");
}

// Create the server with middleware chain
const middlewares = [logger, auth, handler];
const server = http.createServer(compose(middlewares));

server.listen(3000);

compose returns a function (req, res) => { ‚Ä¶ } that iterates through each middleware in order.

Each middleware can do some pre‚Äêprocessing, then call next() to pass control.

If a middleware ends the response (e.g. res.end("‚Ä¶")), it should not call next(), effectively halting the chain.


üîê Security and Data Integrity
15. How do timing attacks work in Node.js, and how can you mitigate them (e.g. during token validation)?
ans :


16. How would you implement HTTP-only, secure cookie-based authentication in Node.js without Express?

17. What are some best practices for preventing injection attacks when using child_process.exec()?

üöÄ Performance, Memory, and Reliability
18. How would you analyze and fix a memory leak in a long-running Node.js server?

19. What‚Äôs the difference between a synchronous memory leak and an asynchronous memory leak in Node.js?